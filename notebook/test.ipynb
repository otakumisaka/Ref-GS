{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84a3c45d-4884-4b60-88db-eb33d10d3981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import torchvision \n",
    "import numpy as np\n",
    "import nvdiffrast.torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scene import Scene\n",
    "from scene.cameras import Camera\n",
    "from argparse import ArgumentParser\n",
    "from arguments import ModelParams, PipelineParams, get_combined_args\n",
    "from gaussian_renderer import render\n",
    "from gaussian_renderer import GaussianModel\n",
    "\n",
    "from diff_surfel_2dgs import GaussianRasterizer as GaussianRasterizer_2dgs\n",
    "from diff_surfel_2dgs import GaussianRasterizationSettings as GaussianRasterizationSettings_2dgs\n",
    "from diff_surfel_rasterization import GaussianRasterizationSettings, GaussianRasterizer\n",
    "from diff_surfel_rasterization_real import GaussianRasterizationSettings as GaussianRasterizationSettings_real\n",
    "from diff_surfel_rasterization_real import GaussianRasterizer as GaussianRasterizer_real\n",
    "\n",
    "from utils.point_utils import depth_to_normal\n",
    "from utils.color_utils import *\n",
    "from utils.sph_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfc6d9b-1828-4010-a8fd-0d58c46157eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/lzhnb/GS-IR\n",
    "from PIL import Image\n",
    "from lpips import LPIPS\n",
    "from utils.loss_utils import ssim as get_ssim\n",
    "\n",
    "def mse(img1: torch.Tensor, img2: torch.Tensor) -> torch.Tensor:\n",
    "    return (((img1 - img2)) ** 2).view(img1.shape[0], -1).mean(1, keepdim=True)\n",
    "\n",
    "def psnr(img1: torch.Tensor, img2: torch.Tensor) -> torch.Tensor:\n",
    "    mse = (((img1 - img2)) ** 2).view(img1.shape[0], -1).mean(1, keepdim=True)\n",
    "    return 20 * torch.log10(1.0 / torch.sqrt(mse))\n",
    "\n",
    "def get_mae(gt_normal_stack: np.ndarray, render_normal_stack: np.ndarray) -> float:\n",
    "    MAE = np.mean(np.arccos(np.clip(np.sum(gt_normal_stack * render_normal_stack, axis=-1), -1, 1)) * 180 / np.pi)\n",
    "    return MAE.item()\n",
    "\n",
    "lpips_fn = LPIPS(net=\"vgg\").cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad26b756-227e-49f5-aeea-868e0e988eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser(description=\"Testing script parameters\")\n",
    "pipeline = PipelineParams(parser)\n",
    "args = ModelParams(parser, sentinel=True)\n",
    "\n",
    "import os\n",
    "\n",
    "# NAME = 'sedan'\n",
    "NAME = 'teapot'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# for small synthetic dataset\n",
    "args.model_path = \"../output/refnerf/\" + NAME\n",
    "args.source_path = \"../data/refnerf/\" + NAME\n",
    "\n",
    "# for large real dataset\n",
    "# args.model_path = \"../output/ref-real/\" + NAME\n",
    "# args.source_path = \"../data/ref-real/\" + NAME\n",
    "\n",
    "args.resolution = 1\n",
    "args.images = \"images\"\n",
    "args.white_background = False\n",
    "args.data_device = \"cpu\"\n",
    "args.model_device = device\n",
    "args.eval = True\n",
    "\n",
    "bg_color = [0, 0, 0]\n",
    "background = torch.tensor(bg_color, dtype=torch.float32, device=device)\n",
    "\n",
    "load_iteration = 30000\n",
    "\n",
    "with torch.no_grad():\n",
    "    gaussians = GaussianModel(args.sh_degree, args)\n",
    "    scene = Scene(args, gaussians, load_iteration=load_iteration, shuffle=False)\n",
    "    gaussians.sph_dim = 16\n",
    "    gaussians.dim = 1\n",
    "    \n",
    "gaussians.light_mlp = torch.load(args.model_path + '/point_cloud/iteration_'+str(load_iteration)+'/light_mlp.pt')\n",
    "gaussians.dir_encoding = torch.load(args.model_path + '/point_cloud/iteration_'+str(load_iteration)+'/dir_encoding.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bfcbbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### For real dataset\n",
    "# Sedan\n",
    "# ENV_CENTER = torch.tensor([-0.032,0.808,0.751], device='cuda')\n",
    "# ENV_RADIUS = 2.138\n",
    "# XYZ = [2, 1, 0]\n",
    "\n",
    "# Gardenspheres\n",
    "# ENV_CENTER = torch.tensor([-0.2270,  1.9700,  1.7740], device='cuda')\n",
    "# ENV_RADIUS = 0.974\n",
    "# XYZ = [2, 1, 0]\n",
    "\n",
    "# # Toycar\n",
    "# ENV_CENTER = torch.tensor([0.486, 1.108, 3.72], device='cuda')\n",
    "# ENV_RADIUS = 2.507\n",
    "# XYZ = [0, 2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3832d666-f10a-4671-91c9-901b477edc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_feature = True\n",
    "\n",
    "def get_outside_msk(xyz, ENV_CENTER, ENV_RADIUS):\n",
    "    device = xyz.device\n",
    "    ENV_CENTER = ENV_CENTER.to(device)\n",
    "    ENV_RADIUS = torch.tensor(ENV_RADIUS, device=device) if not torch.is_tensor(ENV_RADIUS) else ENV_RADIUS.to(device)\n",
    "    return torch.sum((xyz - ENV_CENTER[None])**2, dim=-1) > ENV_RADIUS**2\n",
    "\n",
    "def render(viewpoint_camera, pc, pipe, bg_color, scaling_modifier=1.0, override_color=None, iteration=0):\n",
    "    # Create zero tensor. We will use it to make pytorch return gradients of the 2D (screen-space) means\n",
    "    screenspace_points = torch.zeros_like(pc.get_xyz, dtype=pc.get_xyz.dtype, requires_grad=True, device=\"cuda\") + 0\n",
    "    try:\n",
    "        screenspace_points.retain_grad()\n",
    "    except:\n",
    "        pass\n",
    "    # Set up cuda or cpu device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Set up rasterization configuration\n",
    "    tanfovx = math.tan(viewpoint_camera.FoVx * 0.5)\n",
    "    tanfovy = math.tan(viewpoint_camera.FoVy * 0.5)\n",
    "    \n",
    "    image_height = int(viewpoint_camera.image_height)\n",
    "    image_width = int(viewpoint_camera.image_width)\n",
    "    \n",
    "    raster_settings_black = GaussianRasterizationSettings(\n",
    "        image_height=int(viewpoint_camera.image_height),\n",
    "        image_width=int(viewpoint_camera.image_width),\n",
    "        tanfovx=tanfovx,\n",
    "        tanfovy=tanfovy,\n",
    "        bg=bg_color*0.0,\n",
    "        scale_modifier=scaling_modifier,\n",
    "        viewmatrix=viewpoint_camera.world_view_transform,\n",
    "        projmatrix=viewpoint_camera.full_proj_transform,\n",
    "        sh_degree=pc.active_sh_degree,\n",
    "        campos=viewpoint_camera.camera_center,\n",
    "        prefiltered=False,\n",
    "        debug=False,\n",
    "        include_feature=use_feature,\n",
    "    )\n",
    "    \n",
    "    rasterizer_black = GaussianRasterizer(raster_settings=raster_settings_black)\n",
    "    \n",
    "    means3D = pc.get_xyz\n",
    "    means2D = screenspace_points\n",
    "    opacity = pc.get_opacity\n",
    "    scales = pc.get_scaling\n",
    "    rotations = pc.get_rotation\n",
    "    shs = pc.get_features\n",
    "\n",
    "    rets =  { }\n",
    "\n",
    "    gs_albedo = pc.get_albedo\n",
    "    gs_roughness = pc.get_roughness\n",
    "    gs_feature = pc.get_language_feature\n",
    "\n",
    "    input_ts = torch.cat([gs_roughness, gs_feature], dim=-1)\n",
    "    \n",
    "    albedo_map, out_ts, radii, allmap = rasterizer_black(\n",
    "        means3D = means3D,\n",
    "        means2D = means2D,\n",
    "        shs = None,\n",
    "        colors_precomp = gs_albedo,\n",
    "        language_feature_precomp = input_ts,\n",
    "        opacities = opacity,\n",
    "        scales = scales,\n",
    "        rotations = rotations,\n",
    "        cov3D_precomp = None\n",
    "    )\n",
    "\n",
    "    render_alpha = allmap[1:2]\n",
    "\n",
    "    render_normal = allmap[2:5]\n",
    "    render_normal = (render_normal.permute(1,2,0) @ (viewpoint_camera.world_view_transform[:3,:3].T)).permute(2,0,1)\n",
    "    render_normal = F.normalize(render_normal, dim=0)\n",
    "\n",
    "    render_depth_median = allmap[5:6]\n",
    "    render_depth_median = torch.nan_to_num(render_depth_median, 0, 0)\n",
    "\n",
    "    render_depth_expected = allmap[0:1]\n",
    "    render_depth_expected = (render_depth_expected / render_alpha)\n",
    "    render_depth_expected = torch.nan_to_num(render_depth_expected, 0, 0)\n",
    "\n",
    "    render_dist = allmap[6:7]\n",
    "\n",
    "    surf_depth = render_depth_expected * (1-pipe.depth_ratio) + (pipe.depth_ratio) * render_depth_median\n",
    "\n",
    "    surf_normal = depth_to_normal(viewpoint_camera, surf_depth)\n",
    "    surf_normal = surf_normal.permute(2,0,1)\n",
    "    surf_normal = surf_normal * (render_alpha).detach()\n",
    "\n",
    "    #####################################################################################################################\n",
    "    rays_d = viewpoint_camera.rays_d.cuda()\n",
    "    viewdirs = rays_d\n",
    "    normals = render_normal.permute(1,2,0)\n",
    "    wo = F.normalize(reflect(-viewdirs, normals), dim=-1)\n",
    "    \n",
    "    out_ts = out_ts.permute(1,2,0)\n",
    "    \n",
    "    albedo_map = albedo_map.permute(1,2,0)\n",
    "    roughness_map = out_ts[..., :1]\n",
    "    feature_map = out_ts[..., 1:]\n",
    "    \n",
    "    #####################################################################################################################\n",
    "    with torch.no_grad():\n",
    "        select_index = (render_alpha.reshape(-1,) > 0.05).nonzero(as_tuple=True)[0]\n",
    "    \n",
    "    wo = wo.reshape(-1, 3)[select_index]\n",
    "    normals = normals.reshape(-1, 3)[select_index]\n",
    "    roughness_map = roughness_map.reshape(-1, 1)[select_index]\n",
    "    albedo_map = albedo_map.reshape(-1, 3)[select_index]\n",
    "    \n",
    "    feature_map = feature_map.reshape(-1, pc.gsfeat_dim)[select_index]\n",
    "    feature_map = F.normalize(feature_map, dim=-1)\n",
    "    \n",
    "    feature_map = feature_map.reshape(-1, 1, pc.gsfeat_dim)\n",
    "    feature_dirc = feature_map.reshape(-1, pc.gsfeat_dim)\n",
    "    \n",
    "    ''' Sph-Mip '''\n",
    "    #####################################################################################################################\n",
    "    \n",
    "    wo_xy = (cart2sph(wo.reshape(-1, 3)[..., [0,1,2]])[..., 1:] / torch.Tensor([[np.pi, 2*np.pi]]).to(device))[..., [1,0]]\n",
    "    wo_xyz = torch.stack([wo_xy[:, None, :]], dim=0,)\n",
    "    \n",
    "    spec_level = roughness_map.reshape(-1, 1)\n",
    "\n",
    "    spec_feat = pc.dir_encoding(wo_xyz, spec_level.view(-1, 1), index=0).reshape(-1, pc.sph_dim)\n",
    "    spec_feat_wrap = spec_feat.reshape(-1, pc.sph_dim, 1)\n",
    "    spec_feat_dirc = spec_feat.reshape(-1, pc.sph_dim)\n",
    "    \n",
    "    #####################################################################################################################\n",
    "    # Specular color\n",
    "    wrap_input = (spec_feat_wrap @ feature_map).reshape(-1, pc.sph_dim*pc.gsfeat_dim)\n",
    "    input_mlp = torch.cat([wrap_input, spec_feat_dirc], -1)\n",
    "    mlp_output = pc.light_mlp(input_mlp).float()\n",
    "    spec_light = torch.exp(torch.clamp(mlp_output, max=5.0))\n",
    "    \n",
    "    # Diffuse color\n",
    "    diff_light = albedo_map\n",
    "    \n",
    "    pbr_rgb = spec_light + diff_light\n",
    "    pbr_rgb = linear2srgb(pbr_rgb)\n",
    "    pbr_rgb = torch.clamp(pbr_rgb, min=0., max=1.)\n",
    "    #####################################################################################################################\n",
    "    \n",
    "    output_rgb = torch.zeros(image_height, image_width, 3).to(device)\n",
    "    output_rgb.reshape(-1, 3)[select_index] = pbr_rgb\n",
    "    output_rgb = output_rgb.permute(2,0,1)\n",
    "    \n",
    "    rets.update({\n",
    "        'pred_rgb': output_rgb,\n",
    "        'rend_alpha': render_alpha,\n",
    "        'rend_normal': render_normal,\n",
    "        'rend_dist': render_dist,\n",
    "        'surf_depth': surf_depth,\n",
    "        'feature': feature_map,\n",
    "    })\n",
    "\n",
    "    return rets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b5589e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_real(viewpoint_camera, pc, pipe, bg_color, scaling_modifier=1.0, ENV_CENTER=None, ENV_RADIUS=None, XYZ=[0,1,2]):\n",
    "    screenspace_points = torch.zeros_like(pc.get_xyz, dtype=pc.get_xyz.dtype, requires_grad=True, device=device) + 0\n",
    "    try:\n",
    "        screenspace_points.retain_grad()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Test PointCloud Size\n",
    "    # print screenspace_points\n",
    "    # print scale_modifier\n",
    "    # Set up rasterization configuration\n",
    "    tanfovx = math.tan(viewpoint_camera.FoVx * 0.5)\n",
    "    tanfovy = math.tan(viewpoint_camera.FoVy * 0.5)\n",
    "    \n",
    "    image_height = int(viewpoint_camera.image_height)\n",
    "    image_width = int(viewpoint_camera.image_width)\n",
    "\n",
    "    raster_settings = GaussianRasterizationSettings_2dgs(\n",
    "        image_height=int(viewpoint_camera.image_height),\n",
    "        image_width=int(viewpoint_camera.image_width),\n",
    "        tanfovx=tanfovx,\n",
    "        tanfovy=tanfovy,\n",
    "        bg=bg_color,\n",
    "        scale_modifier=scaling_modifier,\n",
    "        viewmatrix=viewpoint_camera.world_view_transform,\n",
    "        projmatrix=viewpoint_camera.full_proj_transform,\n",
    "        sh_degree=pc.active_sh_degree,\n",
    "        campos=viewpoint_camera.camera_center,\n",
    "        prefiltered=False,\n",
    "        debug=False,\n",
    "    )\n",
    "\n",
    "    raster_settings_black = GaussianRasterizationSettings_real(\n",
    "        image_height=int(viewpoint_camera.image_height),\n",
    "        image_width=int(viewpoint_camera.image_width),\n",
    "        tanfovx=tanfovx,\n",
    "        tanfovy=tanfovy,\n",
    "        bg=bg_color*0.0,\n",
    "        scale_modifier=scaling_modifier,\n",
    "        viewmatrix=viewpoint_camera.world_view_transform,\n",
    "        projmatrix=viewpoint_camera.full_proj_transform,\n",
    "        sh_degree=pc.active_sh_degree,\n",
    "        campos=viewpoint_camera.camera_center,\n",
    "        prefiltered=False,\n",
    "        debug=False,\n",
    "        include_feature=use_feature,\n",
    "    )\n",
    "    \n",
    "    rasterizer = GaussianRasterizer_2dgs(raster_settings=raster_settings)\n",
    "    rasterizer_black = GaussianRasterizer_real(raster_settings=raster_settings_black)\n",
    "    \n",
    "    # print pc get_features method\n",
    "        # print whether shs is empty or zero Tensor\n",
    "    # assert shs is not []\n",
    "    means3D = pc.get_xyz\n",
    "    means2D = screenspace_points\n",
    "    opacity = pc.get_opacity\n",
    "    scales = pc.get_scaling\n",
    "    rotations = pc.get_rotation\n",
    "    shs = pc.get_features\n",
    "\n",
    "    rendered_image, _, _ = rasterizer(\n",
    "        means3D = means3D,\n",
    "        means2D = means2D,\n",
    "        shs = shs,\n",
    "        colors_precomp = None,\n",
    "        opacities = opacity,\n",
    "        scales = scales,\n",
    "        rotations = rotations,\n",
    "        cov3D_precomp = None\n",
    "    )\n",
    "\n",
    "    rets =  {\n",
    "        \"render\": rendered_image,\n",
    "    }\n",
    "\n",
    "    gs_albedo = pc.get_albedo\n",
    "    gs_roughness = pc.get_roughness\n",
    "    gs_mask = pc.get_mask\n",
    "    gs_feature = pc.get_language_feature\n",
    "    \n",
    "    gs_in = gs_mask * 0 + 1.0\n",
    "    gs_in[get_outside_msk(pc.get_xyz, ENV_CENTER, ENV_RADIUS)] = 0.0\n",
    "    \n",
    "    gs_out = gs_mask * 0 + 0.0\n",
    "    gs_out[get_outside_msk(pc.get_xyz, ENV_CENTER, ENV_RADIUS)] = 1.0\n",
    "\n",
    "    input_ts = torch.cat([gs_roughness, gs_feature, gs_in, gs_out], dim=-1)\n",
    "    \n",
    "    albedo_map, out_ts, radii, allmap = rasterizer_black(\n",
    "        means3D = means3D,\n",
    "        means2D = means2D,\n",
    "        shs = None,\n",
    "        colors_precomp = gs_albedo,\n",
    "        language_feature_precomp = input_ts,\n",
    "        opacities = opacity,\n",
    "        scales = scales,\n",
    "        rotations = rotations,\n",
    "        cov3D_precomp = None\n",
    "    )\n",
    "\n",
    "    render_alpha = allmap[1:2]\n",
    "\n",
    "    render_normal = allmap[2:5]\n",
    "    render_normal = (render_normal.permute(1,2,0) @ (viewpoint_camera.world_view_transform[:3,:3].T)).permute(2,0,1)\n",
    "    render_normal = F.normalize(render_normal, dim=0)\n",
    "\n",
    "    render_depth_median = allmap[5:6]\n",
    "    render_depth_median = torch.nan_to_num(render_depth_median, 0, 0)\n",
    "\n",
    "    render_depth_expected = allmap[0:1]\n",
    "    render_depth_expected = (render_depth_expected / (render_alpha))\n",
    "    render_depth_expected = torch.nan_to_num(render_depth_expected, 0, 0)\n",
    "\n",
    "    render_dist = allmap[6:7]\n",
    "\n",
    "    surf_depth = render_depth_expected * (1-pipe.depth_ratio) + (pipe.depth_ratio) * render_depth_median\n",
    "\n",
    "    surf_normal = depth_to_normal(viewpoint_camera, surf_depth)\n",
    "    surf_normal = surf_normal.permute(2,0,1)\n",
    "    surf_normal = surf_normal * (render_alpha).detach()\n",
    "    #####################################################################################################################\n",
    "    \n",
    "    viewdirs = viewpoint_camera.rays_d.to(device)\n",
    "    normals = render_normal.permute(1,2,0)\n",
    "    wo = F.normalize(reflect(-viewdirs, normals), dim=-1)\n",
    "    \n",
    "    out_ts = out_ts.permute(1,2,0)\n",
    "    \n",
    "    albedo_map = albedo_map.permute(1,2,0)\n",
    "    roughness_map = out_ts[..., :1]\n",
    "    feature_map = out_ts[..., 1:5]\n",
    "    in_map = out_ts[..., 5:6]\n",
    "    \n",
    "    #####################################################################################################################\n",
    "    with torch.no_grad():\n",
    "        select_index = (in_map.reshape(-1,) > 0.05).nonzero(as_tuple=True)[0]\n",
    "    \n",
    "    if len(select_index) > 0:\n",
    "    \n",
    "        wo = wo.reshape(-1, 3)[select_index]\n",
    "        normals = normals.reshape(-1, 3)[select_index]\n",
    "        roughness_map = roughness_map.reshape(-1, 1)[select_index]\n",
    "        albedo_map = albedo_map.reshape(-1, 3)[select_index]\n",
    "\n",
    "        feature_map = feature_map.reshape(-1, pc.gsfeat_dim)[select_index]\n",
    "        feature_map = F.normalize(feature_map, dim=-1)\n",
    "\n",
    "        feature_map = feature_map.reshape(-1, 1, pc.gsfeat_dim)\n",
    "        feature_dirc = feature_map.reshape(-1, pc.gsfeat_dim)\n",
    "\n",
    "        ''' Specular env. feature '''\n",
    "        wo_xy = (cart2sph(wo.reshape(-1, 3)[..., XYZ])[..., 1:] / torch.Tensor([[np.pi, 2*np.pi]]).to(device))[..., [1,0]] \n",
    "\n",
    "        wo_xyz = torch.stack([wo_xy[:, None, :]], dim=0,)\n",
    "\n",
    "        spec_level = roughness_map.reshape(-1, 1)\n",
    "        encoding_device = next(pc.dir_encoding.parameters()).device\n",
    "        assert wo_xyz.device == spec_level.device == encoding_device, \\\n",
    "            f\"[Device Mismatch] wo_xyz: {wo_xyz.device}, spec_level: {spec_level.device}, dir_encoding: {encoding_device}\"\n",
    "\n",
    "        \n",
    "        def dir_encoding_patch(pc, wo_xyz, spec_level, index=0, patch_size=100_000):\n",
    "            assert wo_xyz.shape[0] == 1\n",
    "            out = []\n",
    "            for i in range(0, wo_xyz.shape[1], patch_size):\n",
    "                patch_xyz = wo_xyz[:, i:i+patch_size, :]\n",
    "                patch_level = spec_level[i:i+patch_size, :]\n",
    "                enc = pc.dir_encoding(patch_xyz, patch_level.view(-1, 1), index=0).reshape(-1, pc.sph_dim)\n",
    "                out.append(enc)\n",
    "            return torch.cat(out, dim=0)\n",
    "         \n",
    "        spec_feat = dir_encoding_patch(pc, wo_xyz, spec_level.view(-1, 1), index=0).reshape(-1, pc.sph_dim).to(device)\n",
    "        spec_feat_wrap = spec_feat.reshape(-1, pc.sph_dim, 1).to(device)\n",
    "        spec_feat_dirc = spec_feat.reshape(-1, pc.sph_dim).to(device)\n",
    "\n",
    "        #####################################################################################################################\n",
    "        # Specular color\n",
    "        wrap_input = (spec_feat_wrap @ feature_map).reshape(-1, pc.sph_dim*pc.gsfeat_dim)\n",
    "        input_mlp = torch.cat([wrap_input, spec_feat_dirc,], -1)\n",
    "        mlp_output = pc.light_mlp(input_mlp).float()\n",
    "        spec_light = torch.exp(torch.clamp(mlp_output, max=5.0)).to(device)\n",
    "\n",
    "        # Diffuse color\n",
    "        diff_light = albedo_map.to(device)\n",
    "\n",
    "        pbr_rgb = spec_light + diff_light\n",
    "        pbr_rgb = linear2srgb(pbr_rgb)\n",
    "        pbr_rgb = torch.clamp(pbr_rgb, min=0., max=1.).to(device)\n",
    "\n",
    "        #####################################################################################################################\n",
    "\n",
    "        output_rgb = torch.zeros(image_height, image_width, 3).to(device)\n",
    "        output_rgb.reshape(-1, 3)[select_index] = pbr_rgb\n",
    "        output_rgb = output_rgb.permute(2,0,1).to(device)\n",
    "\n",
    "        ref_w = out_ts[..., 5:6].permute(2,0,1).detach().to(device)\n",
    "        out_w = out_ts[..., 6:7].permute(2,0,1).detach().to(device)\n",
    "        full_rgb = ref_w*output_rgb + out_w*rendered_image.to(device)\n",
    "        \n",
    "    else:\n",
    "        full_rgb = rendered_image.to(device)\n",
    "        ref_w = out_ts[..., 5:6].permute(2,0,1).detach().to(device)\n",
    "        out_w = out_ts[..., 6:7].permute(2,0,1).detach().to(device)\n",
    "    \n",
    "    rets.update({\n",
    "        'pred_rgb': full_rgb,\n",
    "        'ref_w': ref_w,\n",
    "        'out_w': out_w,\n",
    "        'ref_index': get_outside_msk(pc.get_xyz, ENV_CENTER, ENV_RADIUS),\n",
    "\n",
    "        'rend_alpha': render_alpha,\n",
    "        'rend_normal': render_normal,\n",
    "        'rend_dist': render_dist,\n",
    "        'surf_depth': surf_depth,\n",
    "        'surf_normal': surf_normal,\n",
    "    })\n",
    "    \n",
    "    return rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb74201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tile_render_real(viewpoint_camera, pc, pipe, bg_color, scale_modifier=1.0, ENV_CENTER=None, ENV_RADIUS=None, XYZ=[0, 1, 2], point_chunk_size=100_000):\n",
    "    \"\"\"\n",
    "    渲染一帧高分辨率图像，按点云 tile 分批渲染避免爆显存\n",
    "    \"\"\"\n",
    "    device = bg_color.device\n",
    "    \n",
    "    image_height = int(viewpoint_camera.image_height)\n",
    "    image_width = int(viewpoint_camera.image_width)\n",
    "\n",
    "    # 初始化最终图像结果\n",
    "    pred_rgb = torch.zeros(3, image_height, image_width, device=device)\n",
    "    pred_alpha = torch.zeros(1, image_height, image_width, device=device)\n",
    "    pred_normal = torch.zeros(3, image_height, image_width, device=device)\n",
    "    acc_alpha = torch.zeros(1, image_height, image_width, device=device)\n",
    "\n",
    "    total_points = pc.get_xyz.shape[0]\n",
    "    print(f\"[PointCloud Size] {total_points}\")\n",
    "    \n",
    "    tile_info_list = []\n",
    "    def transform_world_to_camera(xyz_world: torch.Tensor, camera) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        将点从世界坐标变换到相机坐标\n",
    "        xyz_world: [N, 3]\n",
    "        camera.world_view_transform: [4, 4]\n",
    "        \"\"\"\n",
    "        N = xyz_world.shape[0]\n",
    "        ones = torch.ones((N, 1), device=xyz_world.device)\n",
    "        xyz_homo = torch.cat([xyz_world, ones], dim=1)  # [N, 4]\n",
    "\n",
    "    # 乘以 4x4 变换矩阵\n",
    "        cam_xyz_homo = (camera.world_view_transform @ xyz_homo.T).T  # [N, 4]\n",
    "\n",
    "        return cam_xyz_homo[:, :3]  # 丢掉齐次坐标\n",
    "\n",
    "    \n",
    "    # sort the point cloud by depth\n",
    "    for start in range(0, total_points, point_chunk_size):\n",
    "        end = min(start + point_chunk_size, total_points)\n",
    "        partial_pc = pc.clone_subset(start, end)\n",
    "        cam_xyz = transform_world_to_camera(partial_pc.get_xyz, viewpoint_camera)\n",
    "        avg_depth = cam_xyz[:, 2].mean() \n",
    "        tile_info_list.append({\n",
    "        'avg_depth': avg_depth.item(),\n",
    "        'pc': partial_pc,\n",
    "        })\n",
    "        \n",
    "    tile_info_list.sort(key=lambda x: x['avg_depth'])\n",
    "    \n",
    "    print([tile['avg_depth'] for tile in tile_info_list ])\n",
    "\n",
    "    for tile in tile_info_list:\n",
    "        \n",
    "        partial_pc = tile['pc']\n",
    "        # 渲染该点云子集\n",
    "        with torch.no_grad():\n",
    "            rendering = render_real(viewpoint_camera, partial_pc, pipe, bg_color, scale_modifier, ENV_CENTER, ENV_RADIUS, XYZ)\n",
    "        alpha = rendering['rend_alpha']\n",
    "        rgb = rendering['pred_rgb']\n",
    "        normal = rendering['rend_normal']\n",
    "\n",
    "        T = 1.0 - pred_alpha\n",
    "\n",
    "        pred_rgb += rgb * alpha * T\n",
    "        pred_normal += normal * alpha * T\n",
    "        pred_alpha += alpha * T\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # 归一化\n",
    "    pred_normal = F.normalize(pred_normal + 1e-7, dim=0)\n",
    "\n",
    "    return {\n",
    "        'pred_rgb': pred_rgb,\n",
    "        'rend_alpha': acc_alpha,\n",
    "        'rend_normal': pred_normal\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a1fbfb-4f30-4eda-b26f-652790e72ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_maps = []\n",
    "ref_rgbs = []\n",
    "gt_rgbs = []\n",
    "\n",
    "dataset_test = scene.getTestCameras()\n",
    "\n",
    "for index in tqdm(range(len(dataset_test))):\n",
    "    \n",
    "    pose = copy.deepcopy(dataset_test[index])\n",
    "    \n",
    "    gt_image = pose.original_image.permute(1, 2, 0).cpu()[..., :3]\n",
    "    gt_mask = pose.original_image.permute(1, 2, 0).cpu()[..., 3:]\n",
    "    # print(\"gt_image shape:\", gt_image.shape)\n",
    "    # print(\"gt_mask  shape:\", gt_mask.shape)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ### blender\n",
    "        rendering = render(pose, gaussians, pipeline, background)\n",
    "        \n",
    "        ### real\n",
    "        # rendering = tile_render_real(pose, gaussians, pipeline, background, scale_modifier=1.0, ENV_CENTER=ENV_CENTER, ENV_RADIUS=ENV_RADIUS, XYZ=XYZ)\n",
    "        # rendering = render_real(pose, gaussians, pipeline, background, ENV_CENTER=ENV_CENTER, ENV_RADIUS=ENV_RADIUS, XYZ=XYZ)\n",
    "        \n",
    "        pred_rgb = rendering['pred_rgb'].permute(1, 2, 0).cpu()\n",
    "        normal = (rendering['rend_normal'].permute(1, 2, 0).cpu())\n",
    "        normal = (normal + 1)/2\n",
    "        alpha = rendering['rend_alpha'].permute(1, 2, 0).cpu()\n",
    "\n",
    "        ### blender\n",
    "        ref_rgbs.append(pred_rgb*alpha+(1-alpha))\n",
    "        normal_maps.append(normal*alpha + (1-alpha))\n",
    "        gt_rgbs.append(gt_image*gt_mask+(1-gt_mask))\n",
    "        \n",
    "        ### real\n",
    "        # ref_rgbs.append(pred_rgb)\n",
    "        # normal_maps.append(normal)\n",
    "        # gt_rgbs.append(gt_image)\n",
    "        \n",
    "        del rendering, pred_rgb, normal, alpha\n",
    "        torch.cuda.empty_cache()\n",
    "        import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66895ae5-8e4f-40c2-9bf1-381eca795ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(normal_maps[0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13852ca8-c753-4379-843c-6c469dcaba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ref_rgbs[0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b369cb7-62e5-46b5-8cd4-c0500f471a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gt_rgbs[0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3d2a93-556b-43b6-a9aa-89aae2e4f55d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "psnr_avg = 0.0\n",
    "ssim_avg = 0.0\n",
    "lpips_avg = 0.0\n",
    "\n",
    "eval_num = len(dataset_test)\n",
    "\n",
    "all_psnr = []\n",
    "all_ssim = []\n",
    "all_lpips = []\n",
    "\n",
    "for i in tqdm(range(eval_num)):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        img_gt_img = gt_rgbs[i].permute(2,0,1).to(device)\n",
    "        my_albedo = ref_rgbs[i].permute(2,0,1).to(device)\n",
    "        \n",
    "        one_psnr = psnr(img_gt_img, my_albedo).mean()\n",
    "        one_ssim = get_ssim(img_gt_img, my_albedo).mean()\n",
    "        one_lpips = lpips_fn(img_gt_img, my_albedo).mean()\n",
    "        \n",
    "        psnr_avg += one_psnr\n",
    "        ssim_avg += one_ssim\n",
    "        lpips_avg += one_lpips\n",
    "        \n",
    "        all_psnr.append(one_psnr.item())\n",
    "        all_ssim.append(one_ssim.item())\n",
    "        all_lpips.append(one_lpips.item())\n",
    "    \n",
    "psnr_avg = psnr_avg / eval_num\n",
    "ssim_avg = ssim_avg / eval_num\n",
    "lpips_avg = lpips_avg / eval_num\n",
    "\n",
    "MAE = 0\n",
    "for i in tqdm(range(len(scene.getTestCameras()))):\n",
    "    normal_gt_path = '../data/refnerf/'+NAME+'/test/r_'+ str(i)+'_normal.png'\n",
    "    normal_gt_img = Image.open(normal_gt_path)\n",
    "\n",
    "    normal_gt = np.array(normal_gt_img)[..., :3] / 255  # [H, W, 3] in range [0, 1]\n",
    "    normal_gt = (normal_gt - 0.5) * 2.0\n",
    "    normal_gt = normal_gt / np.linalg.norm(normal_gt, axis=-1, ord=2, keepdims=True)\n",
    "\n",
    "    normal_gs = normal_maps[i].numpy()\n",
    "    normal_gs = (normal_gs - 0.5) * 2.0\n",
    "    normal_gs = normal_gs / np.linalg.norm(normal_gs, axis=-1, ord=2, keepdims=True)\n",
    "    \n",
    "    out = get_mae(normal_gt, normal_gs)\n",
    "    MAE += out\n",
    "    \n",
    "MAE / len(scene.getTestCameras())\n",
    "\n",
    "print(\"#\", NAME, load_iteration, psnr_avg.item(), ssim_avg.item(), lpips_avg.item(), MAE / len(scene.getTestCameras()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3835e76c-d0f0-4e4b-b208-6a94d579b0d3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import imageio\n",
    "# rgb_video = \"rgb.mp4\"\n",
    "# normal_video = \"normal.mp4\"\n",
    "\n",
    "# imageio.mimwrite(rgb_video, ref_rgbs, fps=30, quality=9, macro_block_size=None)\n",
    "# imageio.mimwrite(normal_video, normal_maps, fps=30, quality=9, macro_block_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c122ab6-d232-4786-8ba9-ff2a2ea71b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Video\n",
    "# Video(rgb_video, width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebe7d65f-41f4-4f85-a3e6-9024e3912e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Video\n",
    "# Video(normal_video, width=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ref_gs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
